# Portfolio Insight & Research Platform

The Portfolio Insight & Research Platform is designed to provide users with actionable insights into their investment portfolios by combining structured financial data with unstructured research materials. The system ingests and processes data from multiple sourcesâ€”both internal and externalâ€”leveraging a Relational Database for structured portfolio data, a Vector Database for semantic search over unstructured text, and LLM-powered RAG pipelines for intelligent querying and insights.

## ğŸ¯ Platform Overview

This comprehensive FastAPI-based platform transforms raw financial data into actionable investment intelligence through:

- **Multi-Source Data Integration**: Capitol Hill trades, Yahoo Finance, research reports, and news articles
- **Hybrid Data Architecture**: Relational database for structured data + Vector database for semantic search
- **AI-Powered Insights**: LLM-driven RAG pipelines for intelligent querying and analysis
- **Real-Time Processing**: Live price updates, WebSocket streaming, and automated data ingestion
- **Scalable Architecture**: Industry-standard design for high-performance portfolio management

## ğŸš€ Features

### Core Portfolio Management
- **Portfolio CRUD**: Create, read, update, and delete portfolios
- **Stock Holdings**: Manage individual stock holdings within portfolios
- **User Management**: Multi-user portfolio management
- **Portfolio Analytics**: Real-time portfolio summaries and market value calculations

### Data Scraping & Ingestion
- **Capitol Hill Trades**: Scrape congressional trading data using Firecrawl
- **Yahoo Finance Integration**: Real-time and historical stock data via yfinance
- **Automated Data Ingestion**: Store scraped data in structured database
- **Sample Portfolio Creation**: Generate portfolios from scraped data

### Real-time Price System
- **Live Price Updates**: Real-time stock price streaming via WebSockets
- **Redis Caching**: High-performance price data storage
- **Industry-Standard Architecture**: 5-minute real-time + 24-hour minute data
- **Price History**: Comprehensive historical price tracking

### Vector Database & RAG System
- **Qdrant Integration**: High-performance vector database for semantic search
- **SEC Edgar Downloads**: Automated S&P 500 financial report ingestion
- **OpenAI Embeddings**: Advanced text embeddings for document similarity
- **Semantic Search**: Natural language queries over financial documents
- **Document Processing**: Automated extraction and cleaning of filing content
- **RAG Pipeline**: Retrieval-Augmented Generation for intelligent insights

### Advanced Features
- **WebSocket Streaming**: Live price updates for real-time dashboards
- **RESTful API**: Clean, well-documented API endpoints
- **Comprehensive Testing**: Full test suite with 100% functionality coverage
- **Database Migrations**: Alembic for schema management
- **Graceful Degradation**: Works with or without Redis

## ğŸ—ï¸ Technology Stack

### Backend Framework
- **FastAPI**: Modern, fast web framework for building APIs
- **Uvicorn**: ASGI server for FastAPI
- **Pydantic**: Data validation and serialization

### Database & Storage
- **SQLite**: Primary database for development (easily switchable to PostgreSQL)
- **Redis**: In-memory data store for real-time price caching
- **SQLAlchemy**: Python ORM for database operations
- **Alembic**: Database migration tool

### Data Sources & Scraping
- **Firecrawl**: Web scraping service for Capitol Hill Trades
- **yfinance**: Yahoo Finance API for stock data
- **requests**: HTTP library for web requests
- **BeautifulSoup4**: HTML parsing for web scraping
- **pandas**: Data manipulation and analysis

### Real-time & Caching
- **Redis**: Real-time price caching and time-series data
- **WebSockets**: Bidirectional real-time communication
- **JSON**: Data serialization for real-time updates

### Vector Database & AI
- **Qdrant**: Vector database for semantic search and embeddings
- **OpenAI**: Text embeddings and AI model integration
- **SEC Edgar Downloader**: Automated financial report downloads
- **LlamaIndex**: RAG framework for document processing (future)

### Testing & Development
- **pytest**: Testing framework
- **requests**: HTTP client for API testing
- **websockets**: WebSocket client for testing

### Development Tools
- **Git**: Version control
- **GitHub**: Code repository and collaboration
- **Python Virtual Environment**: Dependency isolation

## ğŸ“ Project Structure

```
Portfolio_Insight_Platform/
â”œâ”€â”€ app/                              # Main application code
â”‚   â”œâ”€â”€ api/                          # API endpoints
â”‚   â”‚   â”œâ”€â”€ portfolio.py              # Portfolio CRUD endpoints
â”‚   â”‚   â”œâ”€â”€ data_ingestion.py         # Data scraping endpoints
â”‚   â”‚   â””â”€â”€ real_time_prices.py       # Real-time price endpoints + WebSocket
â”‚   â”œâ”€â”€ core/                         # Core configuration
â”‚   â”‚   â””â”€â”€ config.py                 # Application settings
â”‚   â”œâ”€â”€ db/                           # Database configuration
â”‚   â”‚   â””â”€â”€ database.py               # SQLAlchemy engine and session
â”‚   â”œâ”€â”€ models/                       # SQLAlchemy models
â”‚   â”‚   â”œâ”€â”€ models.py                 # Core database models
â”‚   â”‚   â””â”€â”€ price_models.py           # Price data models
â”‚   â”œâ”€â”€ schemas/                      # Pydantic schemas
â”‚   â”‚   â””â”€â”€ schemas.py                # API request/response schemas
â”‚   â”œâ”€â”€ services/                     # Business logic
â”‚   â”‚   â”œâ”€â”€ portfolio_service.py      # Portfolio management logic
â”‚   â”‚   â”œâ”€â”€ data_scraper.py           # Web scraping services
â”‚   â”‚   â”œâ”€â”€ data_ingestion.py         # Data storage services
â”‚   â”‚   â””â”€â”€ real_time_price_service.py # Real-time price management
â”‚   â””â”€â”€ main.py                       # FastAPI application entry point
â”œâ”€â”€ alembic/                          # Database migrations
â”‚   â”œâ”€â”€ versions/                     # Migration files
â”‚   â”œâ”€â”€ env.py                        # Alembic environment
â”‚   â””â”€â”€ script.py.mako                # Migration template
â”œâ”€â”€ tests/                            # Test files
â”‚   â”œâ”€â”€ test_portfolio.py             # Portfolio API tests
â”‚   â”œâ”€â”€ test_all_functionalities.py   # Comprehensive test suite
â”‚   â”œâ”€â”€ test_data_scraping.py         # Data scraping tests
â”‚   â””â”€â”€ test_real_time_prices.py      # Real-time price tests
â”œâ”€â”€ docs/                             # Documentation (future)
â”œâ”€â”€ DESIGN_DOC.md                     # Master design specification
â”œâ”€â”€ DESIGN_DIAGRAM.pdf                # System architecture diagram
â”œâ”€â”€ DATABASE_DESIGN.md                # Database design principles & ERD
â”œâ”€â”€ REAL_TIME_PRICES_GUIDE.md         # Real-time architecture documentation
â”œâ”€â”€ VECTOR_SYSTEM_GUIDE.md            # Vector database & RAG system guide
â”œâ”€â”€ requirements.txt                  # Python dependencies
â”œâ”€â”€ alembic.ini                       # Alembic configuration
â”œâ”€â”€ env.example                       # Environment variables template
â”œâ”€â”€ portfolio.db                      # SQLite database (local dev)
â””â”€â”€ README.md                         # This file
```

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.8+**
- **Redis** (for real-time features)
- **Git**

### Installation

1. **Clone the repository:**
```bash
git clone https://github.com/lesleyzhao/Portfolio_Insight_Platform.git
cd Portfolio_Insight_Platform
```

2. **Create and activate virtual environment:**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies:**
```bash
pip install -r requirements.txt
```

4. **Set up environment variables:**
```bash
cp env.example .env
# Edit .env with your configuration
```

5. **Set up Redis (for real-time features):**
```bash
# macOS with Homebrew
brew install redis
brew services start redis

# Ubuntu/Debian
sudo apt-get install redis-server
sudo systemctl start redis

# Or use Docker
docker run -d -p 6379:6379 redis:alpine
```

6. **Set up the database:**
```bash
# Run migrations
alembic upgrade head
```

7. **Run the application:**
```bash
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

The API will be available at `http://localhost:8000`

## ğŸ“š API Documentation

### Interactive Documentation
- **Swagger UI**: `http://localhost:8000/docs`
- **ReDoc**: `http://localhost:8000/redoc`

### API Endpoints

#### Portfolio Management
- `POST /api/v1/portfolios` - Create a new portfolio
- `GET /api/v1/portfolios?user_id={user_id}` - List portfolios for a user
- `GET /api/v1/portfolios/{portfolio_id}?user_id={user_id}` - Get specific portfolio
- `PUT /api/v1/portfolios/{portfolio_id}?user_id={user_id}` - Update portfolio
- `DELETE /api/v1/portfolios/{portfolio_id}?user_id={user_id}` - Delete portfolio

#### Stock Management
- `GET /api/v1/portfolios/{portfolio_id}/stocks?user_id={user_id}` - Get portfolio stocks
- `POST /api/v1/portfolios/{portfolio_id}/stocks?user_id={user_id}` - Add stock to portfolio
- `PATCH /api/v1/portfolios/{portfolio_id}/stocks/{holding_id}?user_id={user_id}` - Update stock holding
- `DELETE /api/v1/portfolios/{portfolio_id}/stocks/{holding_id}?user_id={user_id}` - Remove stock

#### Data Scraping
- `GET /api/v1/data/scrape/capitol-hill-trades` - Scrape Capitol Hill Trades
- `GET /api/v1/data/scrape/stock-data/{ticker}` - Scrape stock data for ticker
- `POST /api/v1/data/ingest/tickers` - Ingest ticker data
- `POST /api/v1/data/ingest/sample-portfolios` - Create sample portfolios

#### Real-time Prices
- `POST /api/v1/prices/update` - Update real-time prices
- `GET /api/v1/prices/realtime/{ticker}` - Get current price
- `GET /api/v1/prices/history/{ticker}` - Get price history (Redis)
- `GET /api/v1/prices/historical/{ticker}` - Get historical prices (Database)
- `GET /api/v1/prices/market-summary` - Get market summary
- `WS /api/v1/prices/ws/{ticker}` - WebSocket for live price updates

#### Portfolio Analytics
- `GET /api/v1/data/portfolios/{portfolio_id}/summary` - Get portfolio summary

## ğŸ›ï¸ Database Schema

### Core Tables
- **`users`** - User accounts and authentication
- **`tickers`** - Stock ticker master data
- **`portfolios`** - Portfolio metadata and settings
- **`holdings_current`** - Current stock holdings in portfolios
- **`prices_daily`** - Daily closing stock prices

### Real-time Data Storage
- **Redis Sorted Sets**: Time-series price data (last 5 minutes)
- **Redis Hash**: Current price data (last 24 hours)
- **PostgreSQL**: Historical daily prices (permanent storage)

## ğŸ”„ Real-time Architecture

### Data Flow
```
External APIs â†’ FastAPI â†’ Redis (Real-time) â†’ PostgreSQL (Historical)
     â†“              â†“
WebSocket â†â”€â”€â”€ Client Dashboard
```

### Storage Strategy
- **Real-time (Redis)**: Last 5 minutes at 1-second intervals
- **Short-term (Redis)**: Last 24 hours at 1-minute intervals  
- **Historical (PostgreSQL)**: Daily closing prices (permanent)

### WebSocket Streaming
- **Endpoint**: `ws://localhost:8000/api/v1/prices/ws/{ticker}`
- **Update Frequency**: 1 second
- **Data Format**: JSON with price, change, volume, timestamp

## ğŸ§ª Testing

### Run All Tests
```bash
# Run comprehensive test suite
python tests/test_all_functionalities.py

# Or run all tests with pytest
pytest tests/ -v
```

### Run Specific Test Suites
```bash
# Portfolio API tests
pytest tests/test_portfolio.py -v

# Data scraping tests
pytest tests/test_data_scraping.py -v

# Real-time price tests
pytest tests/test_real_time_prices.py -v

# Comprehensive functionality test
python tests/test_all_functionalities.py
```

### Test Coverage
- âœ… **Portfolio CRUD** - All operations tested
- âœ… **Data Scraping** - Capitol Hill Trades + Yahoo Finance
- âœ… **Real-time Prices** - Redis integration + WebSocket
- âœ… **Portfolio Analytics** - Summary calculations
- âœ… **Error Handling** - Graceful degradation

## ğŸ”§ Development

### Database Migrations

**Create a new migration:**
```bash
alembic revision --autogenerate -m "Description of changes"
```

**Apply migrations:**
```bash
alembic upgrade head
```

**Rollback migrations:**
```bash
alembic downgrade -1
```

### Environment Variables

Create a `.env` file with:
```env
DATABASE_URL=sqlite:///./portfolio.db
REDIS_URL=redis://localhost:6379
SECRET_KEY=your-secret-key
```

### Adding New Features

1. **API Endpoints**: Add to `app/api/`
2. **Business Logic**: Add to `app/services/`
3. **Database Models**: Add to `app/models/`
4. **API Schemas**: Add to `app/schemas/`
5. **Tests**: Add comprehensive tests
6. **Documentation**: Update README and API docs

## ğŸš€ Production Deployment

### Prerequisites
- **PostgreSQL** (for production database)
- **Redis** (for real-time features)
- **Python 3.8+**
- **Nginx** (reverse proxy)
- **Gunicorn** (WSGI server)

### Environment Setup
```bash
# Install production dependencies
pip install gunicorn

# Set production environment variables
export DATABASE_URL=postgresql://user:pass@localhost/portfolio_db
export REDIS_URL=redis://localhost:6379
export SECRET_KEY=your-production-secret-key
```

### Run Production Server
```bash
gunicorn app.main:app -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000
```

## ğŸ“Š Performance & Scalability

### Redis Performance
- **Memory Usage**: ~300KB per ticker (5 minutes of data)
- **Throughput**: 100,000+ operations per second
- **Latency**: Sub-millisecond response times

### Database Optimization
- **Indexes**: Optimized for portfolio and price queries
- **Connection Pooling**: SQLAlchemy connection management
- **Query Optimization**: Efficient portfolio calculations

### WebSocket Scaling
- **Connection Management**: Efficient WebSocket handling
- **Memory Usage**: Minimal per connection
- **Broadcasting**: Real-time updates to all connected clients

## ğŸ¤ Contributing

1. **Fork the repository**
2. **Create a feature branch**: `git checkout -b feature/amazing-feature`
3. **Make your changes**
4. **Add tests** for new functionality
5. **Run the test suite**: `python test_all_functionalities.py`
6. **Commit your changes**: `git commit -m 'Add amazing feature'`
7. **Push to the branch**: `git push origin feature/amazing-feature`
8. **Open a Pull Request**

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **FastAPI** - Modern web framework
- **Redis** - In-memory data store
- **yfinance** - Yahoo Finance data
- **Firecrawl** - Web scraping service
- **SQLAlchemy** - Python ORM
- **Alembic** - Database migrations

## ğŸ“ Support

For support, email support@portfolio-insight.com or create an issue on GitHub.

---

**Built with â¤ï¸ for the investment community**